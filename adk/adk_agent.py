"""
Agent de Transcri√ß√£o OCR usando Google ADK (Agent Development Kit)
Interface visual de chatbot para processar PDFs e imagens com OCR
"""

import os
import asyncio
import logging
from typing import Optional, Dict, Any, List
from pathlib import Path
import json
import requests

# Carrega vari√°veis de ambiente do arquivo .env
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenv √© opcional

# Google Gemini API imports
try:
    import google.generativeai as genai
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
    GEMINI_AVAILABLE = True
except ImportError:
    # Fallback caso n√£o esteja instalado
    genai = None
    GEMINI_AVAILABLE = False

# OpenAI API imports
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    openai = None
    OPENAI_AVAILABLE = False

# OpenRouter n√£o requer biblioteca especial, usa requests diretamente
OPENROUTER_AVAILABLE = True

# Importa fun√ß√µes do agent de OCR
from api.agent import (
    ocr_with_tesseract,
    ocr_with_easyocr,
    ocr_pdf,
    extract_boleto_fields
)

# Observabilidade centralizada
from api.observability import (
    create_trace, create_span, log_error, is_enabled
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OCRAgent:
    """Agent de OCR usando OpenRouter, OpenAI ou Google Gemini"""
    
    def __init__(self, api_key: Optional[str] = None, provider: Optional[str] = None):
        """
        Inicializa o agent
        
        Args:
            api_key: Chave da API (OpenRouter, OpenAI ou Google)
            provider: "openrouter", "openai" ou "gemini" (auto-detecta se None)
        """
        # Detecta qual provider usar
        openrouter_key = os.getenv("OPENROUTER_API_KEY")
        openai_key = os.getenv("OPENAI_API_KEY")
        google_key = os.getenv("GOOGLE_API_KEY") or api_key
        
        if provider is None:
            # Auto-detec√ß√£o: prioriza OpenRouter, depois OpenAI, depois Gemini
            if openrouter_key and OPENROUTER_AVAILABLE:
                provider = "openrouter"
            elif openai_key and OPENAI_AVAILABLE:
                provider = "openai"
            elif google_key and GEMINI_AVAILABLE:
                provider = "gemini"
            else:
                raise ValueError(
                    "Nenhuma API configurada. Configure OPENROUTER_API_KEY, OPENAI_API_KEY ou GOOGLE_API_KEY. "
                    "Instale: pip install openai (ou google-generativeai)"
                )
        
        self.provider = provider.lower()
        self.api_key = api_key
        
        if self.provider == "openrouter":
            self._init_openrouter(openrouter_key)
        elif self.provider == "openai":
            self._init_openai(openai_key)
        elif self.provider == "gemini":
            self._init_gemini(google_key)
        else:
            raise ValueError(f"Provider inv√°lido: {provider}. Use 'openrouter', 'openai' ou 'gemini'")
        
        # Hist√≥rico de conversa
        self.chat_history = []
    
    def _init_openrouter(self, api_key: Optional[str]):
        """Inicializa cliente OpenRouter"""
        if not OPENROUTER_AVAILABLE:
            raise ImportError("OpenRouter requer biblioteca requests (j√° inclu√≠da)")
        
        self.api_key = api_key or self.api_key or os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY n√£o encontrada. Configure a vari√°vel de ambiente.")
        
        # Modelos OpenRouter em ordem de prefer√™ncia (gratuitos ou baratos)
        # Formato: "provider/model-name"
        model_names = [
            "meta-llama/llama-3.2-3b-instruct",  # Gratuito, leve, FUNCIONA ‚úÖ
            "mistralai/mistral-7b-instruct",    # Gratuito
            "google/gemini-2.0-flash-exp",       # Gratuito, r√°pido (se dispon√≠vel)
            "google/gemini-1.5-flash",           # Gratuito, r√°pido
            "openai/gpt-4o-mini",                # Barato, r√°pido
            "openai/gpt-4o",                     # Mais capaz
            "anthropic/claude-3-haiku",          # R√°pido e eficiente
        ]
        
        self.model_name = None
        self.api_url = "https://openrouter.ai/api/v1/chat/completions"
        
        # Testa cada modelo fazendo uma chamada real
        for model_name in model_names:
            try:
                logger.info(f"üß™ Testando modelo OpenRouter: {model_name}...")
                
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://github.com/your-repo",  # Opcional, mas recomendado
                }
                
                payload = {
                    "model": model_name,
                    "messages": [
                        {"role": "user", "content": "Test"}
                    ],
                    "max_tokens": 5
                }
                
                response = requests.post(
                    self.api_url,
                    headers=headers,
                    json=payload,
                    timeout=15
                )
                
                if response.status_code == 200:
                    self.model_name = model_name
                    logger.info(f"‚úÖ OpenRouter {model_name} configurado e testado com sucesso!")
                    break
                elif response.status_code == 401:
                    logger.warning(f"‚ùå API key inv√°lida para {model_name}")
                    continue
                elif response.status_code == 402:
                    logger.warning(f"‚ö†Ô∏è  Sem cr√©ditos para {model_name}")
                    continue
                else:
                    logger.warning(f"‚ö†Ô∏è  Modelo {model_name} retornou status {response.status_code}")
                    continue
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Erro ao testar modelo {model_name}: {e}")
                continue
        
        if not self.model_name:
            raise ValueError(
                f"Nenhum modelo OpenRouter dispon√≠vel. "
                f"Testados: {', '.join(model_names[:5])}. "
                f"Verifique sua API key e cr√©ditos em https://openrouter.ai"
            )
        
        self.model = None  # OpenRouter usa API HTTP direta
    
    def _init_openai(self, api_key: Optional[str]):
        """Inicializa cliente OpenAI"""
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAI n√£o est√° instalado. Execute: pip install openai")
        
        self.api_key = api_key or self.api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY n√£o encontrada. Configure a vari√°vel de ambiente.")
        
        self.client = openai.OpenAI(api_key=self.api_key)
        
        # Modelos OpenAI em ordem de prefer√™ncia
        model_names = [
            "gpt-4o-mini",      # Mais barato, r√°pido
            "gpt-4o",            # Mais capaz
            "gpt-4-turbo",       # Alternativa
            "gpt-3.5-turbo",     # Fallback
        ]
        
        self.model_name = None
        for model_name in model_names:
            try:
                # Testa se o modelo est√° dispon√≠vel
                self.model_name = model_name
                logger.info(f"‚úÖ OpenAI {model_name} configurado!")
                break
            except Exception as e:
                logger.warning(f"Modelo {model_name} n√£o dispon√≠vel: {e}")
                continue
        
        if not self.model_name:
            raise ValueError("Nenhum modelo OpenAI dispon√≠vel.")
        
        self.model = None  # OpenAI usa client, n√£o model object
    
    def _init_gemini(self, api_key: Optional[str]):
        """Inicializa cliente Gemini"""
        if not GEMINI_AVAILABLE:
            raise ImportError("Google Generative AI n√£o est√° instalado. Execute: pip install google-generativeai")
        
        self.api_key = api_key or self.api_key or os.getenv("GOOGLE_API_KEY")
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY n√£o encontrada. Configure a vari√°vel de ambiente.")
        
        # Configura API do Google
        genai.configure(api_key=self.api_key)
        
        # Tenta diferentes modelos em ordem de prefer√™ncia
        model_names = [
            "gemini-2.0-flash-exp",
            "gemini-pro",
            "gemini-1.5-flash",
            "gemini-1.5-pro",
        ]
        
        self.model = None
        self.model_name = None
        for model_name in model_names:
            try:
                self.model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=self._get_system_instruction(),
                    safety_settings={
                        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                    }
                )
                self.model_name = model_name
                logger.info(f"‚úÖ Gemini {model_name} inicializado com sucesso!")
                break
            except Exception as e:
                logger.warning(f"Modelo {model_name} n√£o dispon√≠vel: {e}")
                continue
        
        if self.model is None:
            raise ValueError("Nenhum modelo Gemini dispon√≠vel. Verifique sua API key.")
    
    def _get_system_instruction(self) -> str:
        """Retorna instru√ß√µes do sistema para o agent"""
        return """Voc√™ √© um assistente especializado em OCR (Reconhecimento √ìptico de Caracteres) 
e extra√ß√£o de dados de boletos banc√°rios.

Suas responsabilidades:
1. Processar PDFs e imagens com OCR
2. Extrair texto de documentos
3. Identificar e extrair campos de boletos (linha digit√°vel, valor, vencimento, etc.)
4. Responder perguntas sobre o conte√∫do extra√≠do
5. Fornecer informa√ß√µes estruturadas sobre os documentos processados

FORMATA√á√ÉO DE RESPOSTAS:
- Sempre formate dados de boletos de forma visual e organizada
- Use emojis relevantes para melhorar a legibilidade
- Organize informa√ß√µes em se√ß√µes claras com separadores visuais
- Destaque informa√ß√µes importantes (valores, datas, c√≥digos)
- Use formata√ß√£o markdown de forma elegante (tabelas, listas, blocos de c√≥digo quando apropriado)

EXEMPLO DE FORMATA√á√ÉO PARA DADOS DE BOLETO:
Use este formato quando apresentar dados extra√≠dos de boletos:

## üìã DADOS DO BOLETO

### Informa√ß√µes Principais
- **üìÖ Data de Vencimento:** 05/11/2025
- **üè¶ Banco:** PicPay Bank
- **üí∞ Valor:** R$ 1.256,00

### Benefici√°rio
- **Nome:** PicPay Bank Banco M√∫ltiplo S.A.
- **CNPJ:** 09.516.419/0001-75

### Pagador
- **Nome:** GABRIELA ROCHA SANTOS FREITAS

### Linha Digit√°vel
```
38090.10006 01429.920059 05875.050311 1 12560000003735
```

---

*Qualquer outra informa√ß√£o que precisar, √© s√≥ perguntar.*

Seja sempre claro, preciso e ofere√ßa informa√ß√µes detalhadas sobre os documentos processados."""
    
    def _get_tools_info(self) -> str:
        """Retorna informa√ß√µes sobre as ferramentas dispon√≠veis"""
        return """
Ferramentas dispon√≠veis:
1. extract_pdf_text(pdf_path, lang="por+eng") - Extrai texto de PDF
2. extract_image_text(image_path, lang="por+eng") - Extrai texto de imagem
3. extract_boleto_data(file_path, lang="por+eng") - Extrai campos de boleto

Use estas ferramentas quando o usu√°rio solicitar processamento de arquivos.
"""
    
    async def extract_pdf_text(self, pdf_path: str, lang: str = "por+eng") -> Dict[str, Any]:
        """Extrai texto de PDF"""
        if not os.path.exists(pdf_path):
            return {"error": f"Arquivo n√£o encontrado: {pdf_path}"}
        
        try:
            pages = ocr_pdf(pdf_path, lang)
            
            # Verifica se encontrou texto significativo
            total_chars = sum(len(p.get('text', '')) for p in pages)
            pages_with_text = sum(1 for p in pages if len(p.get('text', '').strip()) > 20)
            
            full_text = "\n\n".join([f"P√°gina {p['page']}:\n{p['text']}" for p in pages])
            
            # Gera resumo mais informativo
            if total_chars < 50:
                summary = f"AVISO: O PDF foi processado mas pouco ou nenhum texto foi encontrado. {pages_with_text} de {len(pages)} p√°gina(s) cont√™m texto. O arquivo pode estar em branco, ser uma imagem de baixa qualidade, ou conter apenas elementos gr√°ficos."
            else:
                summary = f"Extra√≠do texto de {pages_with_text} de {len(pages)} p√°gina(s). Total de {total_chars} caracteres."
            
            return {
                "success": True,
                "pages": len(pages),
                "text": full_text,
                "summary": summary,
                "total_characters": total_chars,
                "pages_with_text": pages_with_text
            }
        except Exception as e:
            logger.error(f"Erro ao extrair PDF: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}
    
    async def extract_image_text(self, image_path: str, lang: str = "por+eng") -> Dict[str, Any]:
        """Extrai texto de imagem"""
        if not os.path.exists(image_path):
            return {"error": f"Arquivo n√£o encontrado: {image_path}"}
        
        try:
            with open(image_path, "rb") as f:
                content = f.read()
            
            text = ocr_with_tesseract(content, lang)
            
            # Fallback para EasyOCR se necess√°rio
            if len(text.strip()) < 20:
                text = ocr_with_easyocr(content)
            
            return {
                "success": True,
                "text": text,
                "summary": f"Texto extra√≠do com {len(text)} caracteres"
            }
        except Exception as e:
            logger.error(f"Erro ao extrair imagem: {e}")
            return {"error": str(e)}
    
    async def extract_boleto_data(self, file_path: str, lang: str = "por+eng") -> Dict[str, Any]:
        """Extrai campos de boleto"""
        if not os.path.exists(file_path):
            return {"error": f"Arquivo n√£o encontrado: {file_path}"}
        
        try:
            ext = os.path.splitext(file_path)[1].lower()
            
            if ext == ".pdf":
                pages = ocr_pdf(file_path, lang)
                full_text = " ".join([p["text"] for p in pages])
            else:
                with open(file_path, "rb") as f:
                    content = f.read()
                
                text = ocr_with_tesseract(content, lang)
                if len(text.strip()) < 20:
                    text = ocr_with_easyocr(content)
                full_text = text
            
            fields = extract_boleto_fields(full_text)
            
            return {
                "success": True,
                "extracted_fields": fields,
                "text_preview": full_text[:500] + "..." if len(full_text) > 500 else full_text
            }
        except Exception as e:
            logger.error(f"Erro ao extrair boleto: {e}")
            return {"error": str(e)}
    
    async def chat(self, message: str, file_path: Optional[str] = None) -> str:
        """
        Processa uma mensagem do usu√°rio e retorna resposta do agent
        
        Args:
            message: Mensagem do usu√°rio
            file_path: Caminho opcional de arquivo para processar
        
        Returns:
            Resposta do agent
        """
        trace_ctx = create_trace(name="adk_chat", input_data={"message": message[:200]})
        
        if not trace_ctx:
            # Fallback se Langfuse desabilitado
            return await self._chat_internal(message, file_path)
        
        with trace_ctx:
            try:
                # Se houver arquivo, processa primeiro
                context = ""
                file_info = ""
                
                if file_path and os.path.exists(file_path):
                    ext = os.path.splitext(file_path)[1].lower()
                    file_info = f"\n[Arquivo processado: {os.path.basename(file_path)}]"
                    
                    if ext == ".pdf":
                        result = await self.extract_pdf_text(file_path)
                    else:
                        result = await self.extract_image_text(file_path)
                    
                    if result.get("success"):
                        # Verifica se encontrou texto significativo
                        total_chars = result.get('total_characters', 0)
                        pages_with_text = result.get('pages_with_text', 0)
                        summary = result.get('summary', '')
                        
                        if total_chars < 50:
                            # Pouco ou nenhum texto encontrado
                            context = f"\n\n[AVISO IMPORTANTE - Conte√∫do do arquivo]:\n{summary}\n\nO arquivo foi processado mas n√£o foi poss√≠vel extrair texto significativo. Poss√≠veis causas:\n1. O PDF pode estar vazio ou conter apenas imagens/graphics\n2. A qualidade da imagem pode ser muito baixa para OCR\n3. O arquivo pode estar protegido ou criptografado\n4. O texto pode estar em uma fonte n√£o reconhec√≠vel\n\nRecomenda√ß√µes:\n- Verifique se o arquivo est√° correto e cont√©m texto leg√≠vel\n- Tente com um arquivo de melhor qualidade\n- Se for uma fatura/boleto, verifique se n√£o est√° em formato de imagem muito comprimida"
                        else:
                            text_content = result.get('text', result.get('summary', ''))
                            # Limita tamanho para n√£o sobrecarregar o contexto
                            if len(text_content) > 5000:
                                text_content = text_content[:5000] + "\n... (texto truncado)"
                            context = f"\n\n[Conte√∫do extra√≠do do arquivo - {pages_with_text} p√°gina(s) com texto]:\n{text_content}"
                    else:
                        context = f"\n\n[Erro ao processar arquivo]: {result.get('error', 'Erro desconhecido')}"
                
                # Prepara mensagem completa
                full_message = message + file_info + context
                
                # Adiciona ao hist√≥rico
                self.chat_history.append({"role": "user", "parts": [full_message]})
                
                # Gera resposta usando o modelo (OpenRouter, OpenAI ou Gemini)
                provider_name = f"{self.provider}_generate"
                gen_span_ctx = create_span(
                    name=provider_name,
                    input_data={
                        "model": self.model_name,
                        "provider": self.provider,
                        "temperature": 0.7,
                    }
                )
                
                if self.provider == "openrouter":
                    # Usa OpenRouter
                    messages = [
                        {"role": "system", "content": self._get_system_instruction()}
                    ]
                    # Adiciona hist√≥rico (j√° inclui a mensagem atual que foi adicionada acima)
                    for msg in self.chat_history[-10:]:  # √öltimas 10 mensagens
                        role = msg.get("role", "user")
                        if role == "user":
                            messages.append({"role": "user", "content": msg.get("parts", [""])[0]})
                        elif role == "model" or role == "assistant":
                            messages.append({"role": "assistant", "content": msg.get("parts", [""])[0]})
                    
                    headers = {
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                        "HTTP-Referer": "https://github.com/your-repo",  # Opcional, mas recomendado
                    }
                    
                    payload = {
                        "model": self.model_name,
                        "messages": messages,
                        "temperature": 0.7,
                        "max_tokens": 1000
                    }
                    
                    if gen_span_ctx:
                        with gen_span_ctx:
                            response = requests.post(
                                self.api_url,
                                headers=headers,
                                json=payload,
                                timeout=60
                            )
                            response.raise_for_status()
                            result = response.json()
                            response_text = result["choices"][0]["message"]["content"]
                            gen_span_ctx.update(output={"response_preview": response_text[:500]})
                    else:
                        response = requests.post(
                            self.api_url,
                            headers=headers,
                            json=payload,
                            timeout=60
                        )
                        response.raise_for_status()
                        result = response.json()
                        response_text = result["choices"][0]["message"]["content"]
                
                elif self.provider == "openai":
                    # Usa OpenAI
                    messages = [
                        {"role": "system", "content": self._get_system_instruction()}
                    ]
                    # Adiciona hist√≥rico (j√° inclui a mensagem atual que foi adicionada acima)
                    for msg in self.chat_history[-10:]:  # √öltimas 10 mensagens
                        role = msg.get("role", "user")
                        if role == "user":
                            messages.append({"role": "user", "content": msg.get("parts", [""])[0]})
                        elif role == "model" or role == "assistant":
                            messages.append({"role": "assistant", "content": msg.get("parts", [""])[0]})
                    
                    if gen_span_ctx:
                        with gen_span_ctx:
                            response = self.client.chat.completions.create(
                                model=self.model_name,
                                messages=messages,
                                temperature=0.7,
                            )
                            response_text = response.choices[0].message.content
                            gen_span_ctx.update(output={"response_preview": response_text[:500]})
                    else:
                        response = self.client.chat.completions.create(
                            model=self.model_name,
                            messages=messages,
                            temperature=0.7,
                        )
                        response_text = response.choices[0].message.content
                
                else:
                    # Usa Gemini (c√≥digo original)
                    if gen_span_ctx:
                        with gen_span_ctx:
                            response = self.model.generate_content(
                                full_message,
                                generation_config={
                                    "temperature": 0.7,
                                    "top_p": 0.8,
                                    "top_k": 40,
                                }
                            )
                            response_text = response.text
                            gen_span_ctx.update(output={"response_preview": response_text[:500]})
                    else:
                        response = self.model.generate_content(
                            full_message,
                            generation_config={
                                "temperature": 0.7,
                                "top_p": 0.8,
                                "top_k": 40,
                            }
                        )
                        response_text = response.text
                
                # Adiciona resposta ao hist√≥rico
                if self.provider == "openai" or self.provider == "openrouter":
                    role = "assistant"
                else:
                    role = "model"
                self.chat_history.append({"role": role, "parts": [response_text]})
                
                # Limita hist√≥rico (mant√©m √∫ltimas 10 mensagens)
                if len(self.chat_history) > 20:
                    self.chat_history = self.chat_history[-20:]
                
                trace_ctx.update(output={"response_preview": response_text[:200]})
                
                return response_text
                
            except Exception as e:
                logger.error(f"Erro no chat: {e}")
                import traceback
                traceback.print_exc()
                log_error(f"adk_chat_error: {e}")
                trace_ctx.update(output={"error": str(e)})
                return f"‚ùå Erro ao processar: {str(e)}"
    
    async def _chat_internal(self, message: str, file_path: Optional[str] = None) -> str:
        """Implementa√ß√£o interna do chat (sem rastreamento)"""
        # Mesma l√≥gica do chat, mas sem Langfuse
        context = ""
        file_info = ""
        
        if file_path and os.path.exists(file_path):
            ext = os.path.splitext(file_path)[1].lower()
            file_info = f"\n[Arquivo processado: {os.path.basename(file_path)}]"
            
            if ext == ".pdf":
                result = await self.extract_pdf_text(file_path)
            else:
                result = await self.extract_image_text(file_path)
            
            if result.get("success"):
                total_chars = result.get('total_characters', 0)
                pages_with_text = result.get('pages_with_text', 0)
                summary = result.get('summary', '')
                
                if total_chars < 50:
                    context = f"\n\n[AVISO IMPORTANTE - Conte√∫do do arquivo]:\n{summary}\n\nO arquivo foi processado mas n√£o foi poss√≠vel extrair texto significativo."
                else:
                    text_content = result.get('text', result.get('summary', ''))
                    if len(text_content) > 5000:
                        text_content = text_content[:5000] + "\n... (texto truncado)"
                    context = f"\n\n[Conte√∫do extra√≠do do arquivo - {pages_with_text} p√°gina(s) com texto]:\n{text_content}"
            else:
                context = f"\n\n[Erro ao processar arquivo]: {result.get('error', 'Erro desconhecido')}"
        
        full_message = message + file_info + context
        self.chat_history.append({"role": "user", "parts": [full_message]})
        
        response = self.model.generate_content(
            full_message,
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
            }
        )
        
        response_text = response.text
        self.chat_history.append({"role": "model", "parts": [response_text]})
        
        if len(self.chat_history) > 20:
            self.chat_history = self.chat_history[-20:]
        
        return response_text


# Fun√ß√£o para executar o agent via CLI
async def main():
    """Fun√ß√£o principal para executar o agent interativamente"""
    print("ü§ñ Agent de Transcri√ß√£o OCR com Google ADK")
    print("=" * 50)
    print()
    
    # Verifica API key
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("‚ö†Ô∏è  GOOGLE_API_KEY n√£o encontrada!")
        print("   Configure: export GOOGLE_API_KEY='sua-chave-aqui'")
        print()
        api_key = input("Ou digite sua API key agora: ").strip()
        if not api_key:
            print("‚ùå API key obrigat√≥ria!")
            return
    
    try:
        agent = OCRAgent(api_key=api_key)
        print("‚úÖ Agent inicializado com sucesso!")
        print()
        print("üí° Comandos dispon√≠veis:")
        print("   - Digite uma mensagem para conversar")
        print("   - Use 'processar arquivo.pdf' para processar um arquivo")
        print("   - Digite 'sair' para encerrar")
        print()
        
        while True:
            user_input = input("Voc√™: ").strip()
            
            if user_input.lower() in ["sair", "exit", "quit"]:
                print("üëã At√© logo!")
                break
            
            if not user_input:
                continue
            
            # Detecta se h√° caminho de arquivo na mensagem
            file_path = None
            if "processar" in user_input.lower() or "arquivo" in user_input.lower():
                # Tenta extrair caminho do arquivo
                words = user_input.split()
                for word in words:
                    if os.path.exists(word):
                        file_path = word
                        break
            
            print("ü§ñ Agent: ", end="", flush=True)
            response = await agent.chat(user_input, file_path)
            print(response)
            print()
            
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
